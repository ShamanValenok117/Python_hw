{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание к лекции \"Основы веб-скрапинга и работы с API\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1. \n",
    "\n",
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем парсить страницу со свежеми новостям на [habr.com/ru/all/](https://habr.com/ru/all/).\n",
    "\n",
    "Вам необходимо собирать только те статьи, в которых встречается хотя бы одно требуемое ключевое слово. Эти слова определяем в начале кода в переменной, например:\n",
    "\n",
    "`KEYWORDS = ['python', 'парсинг']`\n",
    "\n",
    " Поиск вести по всей доступной preview-информации (это информация, доступная непосредственно с текущей страницы). \n",
    " \n",
    "В итоге должен формироваться датафрейм вида: `<дата> - <заголовок> - <ссылка>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from pymystem3 import Mystem\n",
    "import locale    # Для парсинга даты, которая спрятана в 'req.headers'\n",
    "locale.setlocale(locale.LC_ALL, 'rus_RUS')\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "import pymorphy2 as pym2\n",
    "morph = pym2.MorphAnalyzer()\n",
    "\n",
    "\n",
    "mystem = Mystem()\n",
    "\n",
    "russian_stopwords = set(stopwords.words(\"russian\"))   # Поиск по нмножеству быстрее\n",
    "all_punctuation = set(punctuation)                    # Поиск по нмножеству быстрее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYWORDS = ['python', 'парсинг', 'big', 'data', 'ios', 'cloud', 'android', 'java', 'linux']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'architect', 'associate', 'gcp', 'network', 'опыт', 'экзамен'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Функция разбивки русского текста на леммы. Выдает множество лемм или стемм\n",
    "\n",
    "a = 'Мой опыт с экзаменами GCP: Associate, Architect, Network'\n",
    "\n",
    "def lematizator(sentence, lemm = True , pymorphy = False):\n",
    "    \"\"\" \n",
    "    Функция разбивки русского текста на леммы или стеммы. \n",
    "    Выдает множество лемм  (если lemm = True) \n",
    "    или множество стемм (pymorphy = True)\n",
    "    \"\"\"\n",
    "    words = set( nltk.word_tokenize(sentence) )\n",
    "\n",
    "    without_stop_words = [word.lower() for word in words if (word.lower() not in russian_stopwords) and (word not in all_punctuation) ]\n",
    "\n",
    "    if lemm:\n",
    "        pymorphy = False\n",
    "        without_stop_words_and_lemmatized = [ mystem.lemmatize(word)[0] for word in without_stop_words  ]\n",
    "        return set(without_stop_words_and_lemmatized)\n",
    "    elif pymorphy:\n",
    "        without_stop_words_and_morphytized = [ morph.parse(word)[0].normal_form for word in without_stop_words  ]\n",
    "        return set(without_stop_words_and_morphytized)\n",
    "    else: \n",
    "        return set(without_stop_words)\n",
    "\n",
    "lematizator(a,lemm = False , pymorphy = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Функция вернет время публикации\n",
    "\n",
    "a = 'сегодня в 16:38'\n",
    "\n",
    "def get_post_time(today, yesterday, post_time):\n",
    "    \"\"\" \n",
    "    Функция вернет время публикации  \n",
    "    \"\"\"\n",
    "    if post_time.split()[0] == 'сегодня':\n",
    "        post_time = today.strftime('%Y_%m_%d')  \n",
    "    elif post_time.split()[0] == 'вчера':\n",
    "        post_time = yesterday.strftime('%Y_%m_%d')\n",
    "    else:                    \n",
    "        dd = mystem.lemmatize(post_time)\n",
    "        dd = ''.join(dd)\n",
    "        locale.setlocale(locale.LC_ALL, 'rus_RUS')\n",
    "        post_time_in_datetime = datetime.strptime( dd , '%d %B %Y в %H:%M  \\n')\n",
    "        post_time = post_time_in_datetime.strftime('%Y_%m_%d')\n",
    "        \n",
    "    return post_time\n",
    "\n",
    "#get_post_time(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word = 'ghj'\n",
    "\n",
    "publication_le = {'протокол', 'работа', 'работа', 'пример', 'ftp'}\n",
    "\n",
    "KEYWORDS_in_title = [word for word in KEYWORDS if word in publication_le]\n",
    "KEYWORDS_in_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not (not KEYWORDS_in_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xiaomi Gateway MIEU01 как универсальный контроллер умного дома\n",
      "{'дом', 'универсальный', 'умный', 'контроллер', 'gateway', 'mieu01', 'xiaomi'}\n",
      "HR-тренды 2020-2021: лидерство, wellbeing и антихрупкость\n",
      "{'2020-2021', 'антихрупкость', 'wellbeing', 'hr-тренд', 'лидерство'}\n",
      "Кто использует магнитную плёнку и почему за ней будущее\n",
      "{'почему', 'магнитный', 'будущее', 'плёнка', 'использовать'}\n",
      "Создание исполняемого файла ELF вручную\n",
      "{'создание', 'файл', 'исполняемый', 'elf', 'вручную'}\n",
      "Как мы раскрыли 24-летний баг в ядре Linux\n",
      "{'24-летний', 'ядро', 'баг', 'linux', 'раскрыть'}\n",
      "Совпадение найдено: ['linux']\n",
      "время публикации: 2021_02_22\n",
      "Название публикации: Как мы раскрыли 24-летний баг в ядре Linux\n",
      "Ссылка на публикацию: https://habr.com/ru/company/ruvds/blog/543134/\n",
      "Извилистая геометрия путешествий вокруг света\n",
      "{'вокруг', 'геометрия', 'свет', 'путешествие', 'извилистый'}\n",
      "Как скоро «цифровые люди» захватят приложения для знакомств?\n",
      "{'человек', 'знакомство', '»', 'приложение', 'скоро', 'захватить', '«', 'цифровой'}\n",
      "Аудит событий Active Directory и других решений Microsoft в Quest Change Auditor — анонс вебинара\n",
      "{'вебинар', 'событие', 'change', 'directory', 'аудит', 'active', 'microsoft', 'auditor', 'quest', '—', 'другой', 'анонс', 'решение'}\n",
      "Три года я работал в VSC – и переключился на Lite\n",
      "{'lite', 'vsc', 'переключиться', 'работать', 'год', '–'}\n",
      "Краткость — сестра таланта: Как сделать Transformer/Summarizer на Trax\n",
      "{'trax', 'талант', 'сделать', '—', 'сестра', 'краткость', 'transformer/summarizer'}\n",
      "Законы природы не волнует наше мнение о них\n",
      "{'закон', 'наш', 'мнение', 'природа', 'волновать'}\n",
      "Рейтинг языков программирования 2021: доля Python падает, а TypeScript обошел С++, в лидерах JavaScript, Java, C#\n",
      "{'доля', 'падать', 'с++', 'лидер', 'язык', 'обойти', '2021', 'javascript', 'python', 'typescript', 'java', 'c', 'рейтинг', 'программирование'}\n",
      "Совпадение найдено: ['python', 'java']\n",
      "время публикации: 2021_02_22\n",
      "Название публикации: Рейтинг языков программирования 2021: доля Python падает, а TypeScript обошел С++, в лидерах JavaScript, Java, C#\n",
      "Ссылка на публикацию: https://habr.com/ru/post/543346/\n",
      "Графика в терминале\n",
      "{'терминал', 'графика'}\n",
      "Продолжаем прокачивать Ansible\n",
      "{'продолжать', 'ansible', 'прокачивать'}\n",
      "Что космическая пыль может рассказать о Солнечной системе и Земле\n",
      "{'солнечный', 'рассказать', 'система', 'земля', 'космический', 'пыль'}\n",
      "Дайджест свежих материалов из мира фронтенда за последнюю неделю №455 (15 — 21 февраля 2021)\n",
      "{'21', 'февраль', 'материал', '15', 'фронтенд', 'неделя', 'дайджест', '—', '2021', 'мир', 'свежий', '№455', 'последний'}\n",
      "Интервью с Яной Артищевой: обучение в НИУ ВШЭ ВШБИ и страсть к VR-играм\n",
      "{'vr-игра', 'яна', 'артищев', 'интервью', 'обучение', 'страсть', 'ниу', 'вшбить', 'вшэ'}\n",
      "Какие CMS канут в Лету? Ближайший вектор веб-индустрии для частного сектора\n",
      "{'cms', 'сектор', 'кануть', 'вектор', 'какой', 'веб-индустрия', 'частное', 'лёт', 'близкий'}\n",
      "FOSS News №57 – дайджест материалов о свободном и открытом ПО за 15-21 февраля 2021 года\n",
      "{'февраль', 'news', 'материал', 'свободный', '–', '15-21', '№57', 'дайджест', 'открытый', '2021', 'foss', 'год'}\n",
      "«Переверни игру»: тем, кто стримит лоу-фай музыку, не нужны ни деньги, ни карьера в музыкальной индустрии\n",
      "{'музыкальный', 'лоу-фай', '»', 'деньга', 'перевернуть', 'стримит', 'музыка', 'нужный', 'индустрия', '«', 'карьера', 'игра'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>дата</th>\n",
       "      <th>заголовок</th>\n",
       "      <th>ссылка</th>\n",
       "      <th>ключевое_слово</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_02_22</td>\n",
       "      <td>Как мы раскрыли 24-летний баг в ядре Linux</td>\n",
       "      <td>https://habr.com/ru/company/ruvds/blog/543134/</td>\n",
       "      <td>[linux]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_02_22</td>\n",
       "      <td>Рейтинг языков программирования 2021: доля Pyt...</td>\n",
       "      <td>https://habr.com/ru/post/543346/</td>\n",
       "      <td>[python, java]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         дата                                          заголовок  \\\n",
       "0  2021_02_22         Как мы раскрыли 24-летний баг в ядре Linux   \n",
       "0  2021_02_22  Рейтинг языков программирования 2021: доля Pyt...   \n",
       "\n",
       "                                           ссылка  ключевое_слово  \n",
       "0  https://habr.com/ru/company/ruvds/blog/543134/         [linux]  \n",
       "0                https://habr.com/ru/post/543346/  [python, java]  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Функция main\n",
    "\n",
    "def make_requests( pages = 2, debug = True):\n",
    "    \n",
    "    A = pd.DataFrame(columns = ['дата' , 'заголовок', 'ссылка'] ) \n",
    "    \n",
    "    headers = {\n",
    "        \"Host\" : \"habr.com\",\n",
    "        \"Accept-Encoding\" : \"gzip, deflate, br\",\n",
    "        \"Cache-Control\": \"max-age=0\",\n",
    "        \"Connection\" : \"keep-alive\",\n",
    "        \"Upgrade-Insecure-Requests\": \"1\",\n",
    "        \"Accept\" : \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "        \"Accept-Language\" : \"en-US,en;q=0.5\",\n",
    "        \"User-Agent\" : \"Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:85.0) Gecko/20100101 Firefox/85.0\"\n",
    "                }\n",
    "    \n",
    "    for i in range(pages):\n",
    "        URL = f'https://habr.com/ru/page{i}/'\n",
    "        req1 = requests.get(URL, headers = headers)\n",
    "        \n",
    "        locale.setlocale(locale.LC_ALL, 'en_US')\n",
    "        today = datetime.strptime( req1.headers['Date'] , '%a, %d %b %Y %H:%M:%S %Z')\n",
    "        yesterday = today + timedelta(days = -1)\n",
    "        \n",
    "        time.sleep(0.3)\n",
    "        \n",
    "        soup = BeautifulSoup(req1.text, 'html.parser')\n",
    "        big_post = soup.find_all('article', class_='post post_preview')    \n",
    "        \n",
    "        #------ Разбиваем на публикации \n",
    "        \n",
    "        for element in big_post:         \n",
    "            if element.find('a', class_='post__title_link'):   # Публикация найдена\n",
    " \n",
    "                publication_title = element.find('a', class_='post__title_link').text\n",
    "                if debug: print(publication_title)\n",
    "\n",
    "                #------ Бъем публикацию на леммы (lematizator) и сохраняем в списке 'publication'         \n",
    "                \n",
    "                publication_lemmatized = lematizator(publication_title, lemm = False , pymorphy = True )\n",
    "                if debug: print(publication_lemmatized)\n",
    "                    \n",
    "                KEYWORDS_in_title = [word for word in KEYWORDS if word in publication_lemmatized]\n",
    "\n",
    "                if not (not KEYWORDS_in_title):    # Feel the Force, Luke! KEYWORD is Here!\n",
    "                        post_time = element.find('span', class_='post__time').text.lower()\n",
    "                        post_time = get_post_time(today, yesterday, post_time)\n",
    "                        link = element.find('a', class_='post__title_link').get('href')\n",
    "                         \n",
    "                        if debug:\n",
    "                            print(f'Совпадение найдено: {KEYWORDS_in_title}') \n",
    "                            print(f'время публикации: {post_time}')\n",
    "                            print(f'Название публикации: {publication_title}')\n",
    "                            print(f'Ссылка на публикацию: {link}')\n",
    "                            B = pd.DataFrame( [ [post_time, publication_title, link, KEYWORDS_in_title] ], columns = ['дата','заголовок', 'ссылка', 'ключевое_слово'] )\n",
    "                        else:\n",
    "        #-------------- Добавляем в список полученную публикацию в формате '<дата> - <заголовок> - <ссылка>' ----#        \n",
    "                            B = pd.DataFrame( [ [post_time, publication_title, link] ], columns = ['дата','заголовок', 'ссылка'] )        \n",
    "                        \n",
    "                        A = pd.concat( [ A , B ] )\n",
    "                    \n",
    "            \n",
    "    return A\n",
    "\n",
    "\n",
    "output_report = make_requests(pages=2)\n",
    "output_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть (необязательная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Улучшить скрипт так, чтобы он анализировал не только preview-информацию статьи, но и весь текст статьи целиком.\n",
    "\n",
    "Для этого потребуется получать страницы статей и искать по тексту внутри этой страницы.  \n",
    "\n",
    "Итоговый датафрейм формировать со столбцами: `<дата> - <заголовок> - <ссылка> - <текст_статьи>`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дайджест интересных материалов для мобильного разработчика #382 (15 — 21 февраля)\n",
      "время публикации: 2021_02_21\n",
      "Название публикации: Дайджест интересных материалов для мобильного разработчика #382 (15 — 21 февраля)\n",
      "Ссылка на публикацию: https://habr.com/ru/company/productivity_inside/blog/543528/\n",
      "Ключевое слово:  android\n",
      "Заметки о Unix: история Unix до readline\n",
      "Assembler Editor Plus: Добавление нового микроконтроллера\n",
      "Эффективная конструкция агрегатов. Моделирование одиночного агрегата\n",
      "HackTheBox. Прохождение Feline. RCE через сереализацию в Java и LPE через докер сокеты\n",
      "время публикации: 2021_02_21\n",
      "Название публикации: HackTheBox. Прохождение Feline. RCE через сереализацию в Java и LPE через докер сокеты\n",
      "Ссылка на публикацию: https://habr.com/ru/post/542612/\n",
      "Ключевое слово: java \n",
      "Linux, suspend to RAM и ИБП\n",
      "время публикации: 2021_02_21\n",
      "Название публикации: Linux, suspend to RAM и ИБП\n",
      "Ссылка на публикацию: https://habr.com/ru/post/543514/\n",
      "Ключевое слово: linux \n",
      "Личный кабинет адаптации сотрудника на Microsoft Power Platform и Microsoft Teams\n",
      "Решение уравнения тетраэдра доказано спустя десятки лет после компьютерного поиска\n",
      "Работа с FTP протоколом в Android. Пример\n",
      "время публикации: 2021_02_20\n",
      "Название публикации: Работа с FTP протоколом в Android. Пример\n",
      "Ссылка на публикацию: https://habr.com/ru/post/543502/\n",
      "Ключевое слово: android \n",
      "Герундий, что ты такое?\n",
      "Радикальный перфекционизм в коде\n",
      "Пол Грэм: Над чем я работал\n",
      "Хитрости работы с MeshLab: устранение ошибок в 3D моделях\n",
      "Из-за пандемии потребление интернет-трафика превысило ожидаемые значения в 1,5 раза\n",
      "время публикации: 2021_02_20\n",
      "Название публикации: Из-за пандемии потребление интернет-трафика превысило ожидаемые значения в 1,5 раза\n",
      "Ссылка на публикацию: https://habr.com/ru/company/selectel/blog/543482/\n",
      "Ключевое слово:  cloud\n",
      "Делаем систему контроля и управления доступом (СКУД) для умного дома\n",
      "время публикации: 2021_02_20\n",
      "Название публикации: Делаем систему контроля и управления доступом (СКУД) для умного дома\n",
      "Ссылка на публикацию: https://habr.com/ru/post/543446/\n",
      "Ключевое слово:  data\n",
      "UUID и браузеры. Почему фронтенд живет без страшных айдишников?\n",
      "Поддержка токенов PKCS#11 с ГОСТ-криптографией в Python. Часть I\n",
      "время публикации: 2021_02_20\n",
      "Название публикации: Поддержка токенов PKCS#11 с ГОСТ-криптографией в Python. Часть I\n",
      "Ссылка на публикацию: https://habr.com/ru/post/542182/\n",
      "Ключевое слово: python \n",
      "Стоимость переезда в Португалию из России\n",
      "Гибкое управление бизнес-процессами и роль информационных систем\n",
      "Темы, стили и атрибуты\n",
      "время публикации: 2021_02_20\n",
      "Название публикации: Темы, стили и атрибуты\n",
      "Ссылка на публикацию: https://habr.com/ru/post/543460/\n",
      "Ключевое слово:  android\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>дата</th>\n",
       "      <th>заголовок</th>\n",
       "      <th>ссылка</th>\n",
       "      <th>текст_статьи</th>\n",
       "      <th>ключевое слово</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_02_21</td>\n",
       "      <td>Дайджест интересных материалов для мобильного ...</td>\n",
       "      <td>https://habr.com/ru/company/productivity_insid...</td>\n",
       "      <td>В этом выпуске цвета Swift, переиспользуемый ч...</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_02_21</td>\n",
       "      <td>HackTheBox. Прохождение Feline. RCE через сере...</td>\n",
       "      <td>https://habr.com/ru/post/542612/</td>\n",
       "      <td>Продолжаю публикацию решений отправленных на д...</td>\n",
       "      <td>java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_02_21</td>\n",
       "      <td>Linux, suspend to RAM и ИБП</td>\n",
       "      <td>https://habr.com/ru/post/543514/</td>\n",
       "      <td>В случае периодических, но достаточно кратковр...</td>\n",
       "      <td>linux</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_02_20</td>\n",
       "      <td>Работа с FTP протоколом в Android. Пример</td>\n",
       "      <td>https://habr.com/ru/post/543502/</td>\n",
       "      <td>Всем привет! Это будет очень маленькая статья....</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_02_20</td>\n",
       "      <td>Из-за пандемии потребление интернет-трафика пр...</td>\n",
       "      <td>https://habr.com/ru/company/selectel/blog/543482/</td>\n",
       "      <td>Компания TeleGeography проанализировала показа...</td>\n",
       "      <td>cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_02_20</td>\n",
       "      <td>Делаем систему контроля и управления доступом ...</td>\n",
       "      <td>https://habr.com/ru/post/543446/</td>\n",
       "      <td>ВведениеПримерно год назад я начал готовиться ...</td>\n",
       "      <td>data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_02_20</td>\n",
       "      <td>Поддержка токенов PKCS#11 с ГОСТ-криптографией...</td>\n",
       "      <td>https://habr.com/ru/post/542182/</td>\n",
       "      <td>Поддержка криптографических токенов PKCS#11 с ...</td>\n",
       "      <td>python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021_02_20</td>\n",
       "      <td>Темы, стили и атрибуты</td>\n",
       "      <td>https://habr.com/ru/post/543460/</td>\n",
       "      <td>В Android существуют стили и темы которые позв...</td>\n",
       "      <td>android</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         дата                                          заголовок  \\\n",
       "0  2021_02_21  Дайджест интересных материалов для мобильного ...   \n",
       "0  2021_02_21  HackTheBox. Прохождение Feline. RCE через сере...   \n",
       "0  2021_02_21                        Linux, suspend to RAM и ИБП   \n",
       "0  2021_02_20          Работа с FTP протоколом в Android. Пример   \n",
       "0  2021_02_20  Из-за пандемии потребление интернет-трафика пр...   \n",
       "0  2021_02_20  Делаем систему контроля и управления доступом ...   \n",
       "0  2021_02_20  Поддержка токенов PKCS#11 с ГОСТ-криптографией...   \n",
       "0  2021_02_20                             Темы, стили и атрибуты   \n",
       "\n",
       "                                              ссылка  \\\n",
       "0  https://habr.com/ru/company/productivity_insid...   \n",
       "0                   https://habr.com/ru/post/542612/   \n",
       "0                   https://habr.com/ru/post/543514/   \n",
       "0                   https://habr.com/ru/post/543502/   \n",
       "0  https://habr.com/ru/company/selectel/blog/543482/   \n",
       "0                   https://habr.com/ru/post/543446/   \n",
       "0                   https://habr.com/ru/post/542182/   \n",
       "0                   https://habr.com/ru/post/543460/   \n",
       "\n",
       "                                        текст_статьи ключевое слово  \n",
       "0  В этом выпуске цвета Swift, переиспользуемый ч...        android  \n",
       "0  Продолжаю публикацию решений отправленных на д...          java   \n",
       "0  В случае периодических, но достаточно кратковр...         linux   \n",
       "0  Всем привет! Это будет очень маленькая статья....       android   \n",
       "0  Компания TeleGeography проанализировала показа...          cloud  \n",
       "0  ВведениеПримерно год назад я начал готовиться ...           data  \n",
       "0  Поддержка криптографических токенов PKCS#11 с ...        python   \n",
       "0  В Android существуют стили и темы которые позв...        android  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_function(pages = 1 , debug = True):\n",
    "    for i in range(1, pages + 1,1):\n",
    "        URL = f'https://habr.com/ru/page{i}/'\n",
    "        \n",
    "        req = requests.get(URL)\n",
    "        A = pd.DataFrame(columns = ['дата' , 'заголовок', 'ссылка', 'текст_статьи'] )\n",
    "\n",
    "        time.sleep(0.3)\n",
    "\n",
    "        locale.setlocale(locale.LC_ALL, 'en_US')\n",
    "        today = datetime.strptime( req.headers['Date'] , '%a, %d %b %Y %H:%M:%S %Z')\n",
    "        yesterday = today + timedelta(days = -1)\n",
    "\n",
    "        soup = BeautifulSoup(req.text, 'html.parser')\n",
    "        links = [element.get('href') for element in soup.find_all('a', class_='post__title_link') ]\n",
    "        \n",
    "        for link in links:\n",
    "            req = requests.get(link)\n",
    "            soup = BeautifulSoup(req.text, 'html.parser')\n",
    "\n",
    "            time.sleep(0.5)\n",
    "\n",
    "            publicaton_title = soup.find('span', class_='post__title-text').text\n",
    "            if debug: print(publicaton_title)\n",
    "            publicaton_text = soup.find('div', class_='post__body post__body_full').text.replace('\\n','').replace('\\r','')\n",
    "\n",
    "            lemmatized_publicaton_title = lematizator(publicaton_title, lemm = False , pymorphy = True )\n",
    "            KEYWORDS_in_title = [word for word in lemmatized_publicaton_title if word in set(KEYWORDS)]\n",
    "\n",
    "            if (not KEYWORDS_in_title):\n",
    "                lemmatized_publicaton_text = lematizator(publicaton_text, lemm = False , pymorphy = True )\n",
    "                KEYWORDS_in_text = [word for word in lemmatized_publicaton_text if word in set(KEYWORDS)]\n",
    "                if (not KEYWORDS_in_text): continue\n",
    "            else: \n",
    "                KEYWORDS_in_text = []\n",
    "\n",
    "         # Нашли ключевое слово\n",
    "            post_time = soup.find('span', class_='post__time').text.lower()\n",
    "            post_time = get_post_time(today, yesterday, post_time)\n",
    "\n",
    "            if debug:\n",
    "                print(f'время публикации: {post_time}')\n",
    "                print(f'Название публикации: {publicaton_title}')\n",
    "                print(f'Ссылка на публикацию: {link}')\n",
    "                #print(f'Текст публикации: {publicaton_text}') \n",
    "                found_keyword = ''.join(KEYWORDS_in_title +[\" \"]+ KEYWORDS_in_text)\n",
    "                print(f'Ключевое слово: {found_keyword}')\n",
    "                print()\n",
    "                B = pd.DataFrame( [ [post_time, publicaton_title, link, publicaton_text, found_keyword] ], columns = ['дата','заголовок', 'ссылка', 'текст_статьи', 'ключевое слово'] )        \n",
    "            else:\n",
    "                B = pd.DataFrame( [ [post_time, publicaton_title, link, publicaton_text] ], columns = ['дата','заголовок', 'ссылка', 'текст_статьи'] )        \n",
    "\n",
    "            A = pd.concat( [ A , B ] ) \n",
    "\n",
    "    return A\n",
    "\n",
    "check_function(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обязательная часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет проверять список e-mail адресов на утечку при помощи сервиса [Avast Hack Ckeck](https://www.avast.com/hackcheck/).\n",
    "Список email-ов задаем переменной в начале кода:  \n",
    "`EMAIL = [xxx@x.ru, yyy@y.com]`\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: `<почта> - <дата утечки> - <источник утечки> - <описание утечки>`  \n",
    "\n",
    "**Подсказка**: сервис работает при помощи \"скрытого\" API. Внимательно изучите post-запросы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kate1991@yandex.ru\n",
      "yyy@y.com\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>почта</th>\n",
       "      <th>дата утечки</th>\n",
       "      <th>источник утечки</th>\n",
       "      <th>описание утечки</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>kate1991@yandex.ru</td>\n",
       "      <td>2016_10_29</td>\n",
       "      <td>vk.com</td>\n",
       "      <td>Popular Russian social networking platform VKo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2020_01_03</td>\n",
       "      <td>azcentral.com</td>\n",
       "      <td>At an unconfirmed date, online Arizona newspap...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2020_05_28</td>\n",
       "      <td>wishbone.io</td>\n",
       "      <td>In January 2020, the online poll website Wishb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017_11_04</td>\n",
       "      <td>myheritage.com</td>\n",
       "      <td>In October 2017, a customer database belonging...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2021_02_11</td>\n",
       "      <td>forums.vkmonline.com</td>\n",
       "      <td>At an unconfirmed date, the Russian-language m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2019_06_13</td>\n",
       "      <td>canva.com</td>\n",
       "      <td>In May 2019, graphic-design site Canva's datab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016_10_24</td>\n",
       "      <td>dropbox.com</td>\n",
       "      <td>Cloud storage company Dropbox suffered a major...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016_10_21</td>\n",
       "      <td>linkedin.com</td>\n",
       "      <td>In 2012, online professional networking platfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017_03_01</td>\n",
       "      <td>rayli.com.cn</td>\n",
       "      <td>On an unconfirmed date, Chinese gossip site Ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2019_10_17</td>\n",
       "      <td>zynga.com</td>\n",
       "      <td>In September 2019, the game developer Zynga wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016_10_21</td>\n",
       "      <td>adobe.com</td>\n",
       "      <td>In October of 2013, criminals penetrated Adobe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2018_02_18</td>\n",
       "      <td>netlog.com</td>\n",
       "      <td>Netlog (formerly known as Facebox and Bingbox)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017_03_15</td>\n",
       "      <td>globalreach.eu</td>\n",
       "      <td>In 2016, Global Reach Technology's database wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2016_10_23</td>\n",
       "      <td>imesh.com</td>\n",
       "      <td>In June 2016, a cache of over 51 million user ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>yyy@y.com</td>\n",
       "      <td>2017_03_24</td>\n",
       "      <td>youku.com</td>\n",
       "      <td>Youku is a large Chinese video content company...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index               почта дата утечки       источник утечки  \\\n",
       "0       0  kate1991@yandex.ru  2016_10_29                vk.com   \n",
       "1       0           yyy@y.com  2020_01_03         azcentral.com   \n",
       "2       0           yyy@y.com  2020_05_28           wishbone.io   \n",
       "3       0           yyy@y.com  2017_11_04        myheritage.com   \n",
       "4       0           yyy@y.com  2021_02_11  forums.vkmonline.com   \n",
       "5       0           yyy@y.com  2019_06_13             canva.com   \n",
       "6       0           yyy@y.com  2016_10_24           dropbox.com   \n",
       "7       0           yyy@y.com  2016_10_21          linkedin.com   \n",
       "8       0           yyy@y.com  2017_03_01          rayli.com.cn   \n",
       "9       0           yyy@y.com  2019_10_17             zynga.com   \n",
       "10      0           yyy@y.com  2016_10_21             adobe.com   \n",
       "11      0           yyy@y.com  2018_02_18            netlog.com   \n",
       "12      0           yyy@y.com  2017_03_15        globalreach.eu   \n",
       "13      0           yyy@y.com  2016_10_23             imesh.com   \n",
       "14      0           yyy@y.com  2017_03_24             youku.com   \n",
       "\n",
       "                                      описание утечки  \n",
       "0   Popular Russian social networking platform VKo...  \n",
       "1   At an unconfirmed date, online Arizona newspap...  \n",
       "2   In January 2020, the online poll website Wishb...  \n",
       "3   In October 2017, a customer database belonging...  \n",
       "4   At an unconfirmed date, the Russian-language m...  \n",
       "5   In May 2019, graphic-design site Canva's datab...  \n",
       "6   Cloud storage company Dropbox suffered a major...  \n",
       "7   In 2012, online professional networking platfo...  \n",
       "8   On an unconfirmed date, Chinese gossip site Ra...  \n",
       "9   In September 2019, the game developer Zynga wa...  \n",
       "10  In October of 2013, criminals penetrated Adobe...  \n",
       "11  Netlog (formerly known as Facebox and Bingbox)...  \n",
       "12  In 2016, Global Reach Technology's database wa...  \n",
       "13  In June 2016, a cache of over 51 million user ...  \n",
       "14  Youku is a large Chinese video content company...  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "EMAIL = ['kate1991@yandex.ru', 'yyy@y.com']\n",
    "\n",
    "def check_email_for_leak(EMAIL):\n",
    "    \n",
    "    A = pd.DataFrame(columns = ['почта' , 'дата утечки', 'источник утечки', 'описание утечки'] )\n",
    "\n",
    "    URL = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'\n",
    "\n",
    "    headers = {\n",
    "\n",
    "        'User-Agent ': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:85.0) Gecko/20100101 Firefox/85.0',\n",
    "        'Vaar-Header-App-Product' : 'hackcheck-web-avast',\n",
    "        'Vaar-Header-App-Product-Name' : 'hackcheck-web-avast',\n",
    "        'Vaar-Header-Build-Version' : '{__VERSION__}',\n",
    "        'Vaar-Version' : '0',\n",
    "        'Content-Type' : 'application/json;charset=utf-8',\n",
    "        'Content-Length' : '41',\n",
    "        'Origin' : 'https://www.avast.com',\n",
    "        'Referer' : 'https://www.avast.com/hackcheck/'\n",
    "        } \n",
    "    for email in EMAIL:\n",
    "        print(email)\n",
    "        params = { 'emailAddresses' : [ email ]  }\n",
    "\n",
    "        req = requests.post(URL , data = json.dumps(params) , headers = headers)\n",
    "\n",
    "        time.sleep(5)\n",
    "\n",
    "        if not req.json():continue\n",
    "\n",
    "        C = req.json()\n",
    "        C['breaches'].keys()\n",
    "        for breach_id in C['breaches'].keys():\n",
    "            breach_source = C['breaches'][breach_id]['site']\n",
    "            breach_description = req.json()['breaches'][breach_id]['description']\n",
    "            breach_date = req.json()['breaches'][breach_id]['publishDate']\n",
    "            breach_date_in_datetime = datetime.strptime( breach_date , '%Y-%m-%dT%H:%M:%SZ')\n",
    "            breach_date = breach_date_in_datetime.strftime('%Y_%m_%d')\n",
    "            B = pd.DataFrame( [ [email, breach_date, breach_source, breach_description ] ], columns = ['почта' , 'дата утечки', 'источник утечки', 'описание утечки'] )        \n",
    "            A = pd.concat( [ A , B ] )\n",
    "    A = A.reset_index()\n",
    "    return A\n",
    "\n",
    "leaked_emails = check_email_for_leak(EMAIL)\n",
    "leaked_emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Дополнительная часть (необязательная)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Написать скрипт, который будет получать 50 последних постов указанной группы во Вконтакте.  \n",
    "Документация к API VK: https://vk.com/dev/methods\n",
    ", вам поможет метод [wall.get](https://vk.com/dev/wall.get)  \n",
    "```\n",
    "GROUP = 'netology'  \n",
    "TOKEN = УДАЛЯЙТЕ В ВЕРСИИ ДЛЯ ПРОВЕРКИ, НА GITHUB НЕ ВЫКЛАДЫВАТЬ  \n",
    "```\n",
    "\n",
    "В итоге должен формироваться датафрейм со столбцами: `<дата поста> - <текст поста>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "у меня нет профиля Вконтакте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ПРИМЕЧАНИЕ\n",
    "Домашнее задание сдается ссылкой на репозиторий [GitHub](https://github.com/).\n",
    "Не сможем проверить или помочь, если вы пришлете:\n",
    "- файлы;\n",
    "- архивы;\n",
    "- скриншоты кода.\n",
    "\n",
    "Все обсуждения и консультации по выполнению домашнего задания ведутся только на соответствующем канале в slack.\n",
    "\n",
    "##### Как правильно задавать вопросы аспирантам, преподавателям и коллегам?\n",
    "Прежде чем задать вопрос необходимо попробовать найти ответ самому в интернете. Навык самостоятельного поиска информации – один из важнейших, и каждый практикующий специалист любого уровня это делает каждый день.\n",
    "\n",
    "Любой вопрос должен быть сформулирован по алгоритму:  \n",
    "1) Что я делаю?  \n",
    "2) Какого результата я ожидаю?  \n",
    "3) Как фактический результат отличается от ожидаемого?  \n",
    "4) Что я уже попробовал сделать, чтобы исправить проблему?  \n",
    "\n",
    "По возможности, прикрепляйте к вопросу скриншоты, либо ссылки на код. Оставляйте только проблемный и воспроизводимый участок кода, все решение выкладывать не допускается.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
